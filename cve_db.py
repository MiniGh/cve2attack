import requests
import json
import os
import time
import re
from tqdm import tqdm
from pathlib import Path
from datetime import datetime

# ====== é…ç½® ======
API_KEY = "YOUR_API_KEY_HERE"  # â† â† â† æ›¿æ¢ä¸ºä½ çš„ API Keyï¼ˆå¼ºçƒˆå»ºè®®ï¼‰
HEADERS = {"apiKey": API_KEY} if API_KEY != "YOUR_API_KEY_HERE" else {}
BASE_URL = "https://services.nvd.nist.gov/rest/json/cves/2.0"

OUTPUT_DIR = Path("./source/cve")
OUTPUT_DIR.mkdir(exist_ok=True)

# åˆ†é¡µå‚æ•°ï¼ˆNVD é™åˆ¶ï¼šmax 2000/pageï¼‰
RESULTS_PER_PAGE = 2000

# é‡è¯•é…ç½®
MAX_RETRIES = 3
RETRY_DELAY = 5  # ç§’


def fetch_with_retry(url, params, headers, retries=MAX_RETRIES):
    for i in range(retries + 1):
        try:
            response = requests.get(url, params=params, headers=headers, timeout=30)
            if response.status_code == 200:
                return response.json()
            elif response.status_code == 403:
                print(f"âš ï¸  Rate limited (403). Retrying in {RETRY_DELAY}s... (attempt {i+1}/{retries+1})")
            elif response.status_code == 503:
                print(f"âš ï¸  Service unavailable (503). Retrying in {RETRY_DELAY}s...")
            else:
                print(f"âŒ HTTP {response.status_code}: {response.text[:200]}")
            if i < retries:
                time.sleep(RETRY_DELAY * (2 ** i))  # æŒ‡æ•°é€€é¿
        except Exception as e:
            print(f"âŒ Request failed: {e}. Retrying in {RETRY_DELAY}s...")
            if i < retries:
                time.sleep(RETRY_DELAY)
    raise RuntimeError(f"Failed to fetch {url} after {retries} retries")


def extract_cwe_list(weaknesses):
    """æŒ‰ä½ çš„é€»è¾‘ï¼šä¼˜å…ˆ Primaryï¼Œå† Secondaryï¼›åªå– CWE-æ•°å­—"""
    primary_cwes = []
    secondary_cwes = []
    
    for w in weaknesses:
        w_type = w.get("type", "")
        desc_list = w.get("description", [])
        if not desc_list:
            continue
        cwe_val = desc_list[0].get("value", "")
        # åŒ¹é… CWE-123 æˆ– CWE-1234ï¼ˆä¸¥æ ¼ï¼‰
        match_obj = re.match(r"CWE-(\d{1,5})", cwe_val)
        if not match_obj:
            continue
        cwe_num = match_obj.group(1)
        
        if w_type == "Primary":
            primary_cwes.append(cwe_num)
        elif w_type == "Secondary":
            secondary_cwes.append(cwe_num)
    
    # ä¼˜å…ˆç”¨ Primaryï¼›è‹¥æ— ï¼Œåˆ™ç”¨ Secondary
    return sorted(set(primary_cwes)) if primary_cwes else sorted(set(secondary_cwes))


def main():
    print("[ğŸš€] Starting full NVD CVE fetch (by year)...")
    
    # Step 1: è·å–æ€»æ•°ï¼ˆç”¨äºåˆ†é¡µï¼‰
    print("[ğŸ”] Fetching total CVE count...")
    try:
        data = fetch_with_retry(BASE_URL, {"resultsPerPage": 1}, HEADERS)
        total_results = data["totalResults"]
        print(f"[âœ…] Total CVEs: {total_results:,}")
    except Exception as e:
        print(f"[âŒ] Failed to get total: {e}")
        return

    # Step 2: åˆ†é¡µæ‹‰å–
    total_pages = (total_results + RESULTS_PER_PAGE - 1) // RESULTS_PER_PAGE
    print(f"[ğŸ“Š] Total pages: {total_pages}")

    year_buckets = {}  # { "2017": { "CVE-2017-0001": {...}, ... }, ... }

    for page in tqdm(range(total_pages), desc="Pages", unit="page"):
        start_index = page * RESULTS_PER_PAGE
        params = {
            "resultsPerPage": RESULTS_PER_PAGE,
            "startIndex": start_index
        }

        # æ‹‰å–ä¸€é¡µ
        try:
            data = fetch_with_retry(BASE_URL, params, HEADERS)
        except Exception as e:
            print(f"\n[ğŸ›‘] Page {page} failed. Skip. ({e})")
            continue

        # å¤„ç†æ¯ä¸ª CVE
        for item in tqdm(data.get("vulnerabilities", []), desc=f"Page {page}", leave=False, unit="CVE"):
            cve_obj = item.get("cve", {})
            cve_id = cve_obj.get("id", "")
            if not cve_id or not cve_id.startswith("CVE-"):
                continue

            # æå–å¹´ä»½
            try:
                year = cve_id.split("-")[1]
                if not year.isdigit() or len(year) != 4:
                    year = "unknown"
            except:
                year = "unknown"

            # æå–è‹±æ–‡æè¿°
            description = ""
            for desc in cve_obj.get("descriptions", []):
                if desc.get("lang") == "en":
                    description = desc.get("value", "").strip()
                    break

            # æå– CWEsï¼ˆæŒ‰ä½ çš„é€»è¾‘ï¼‰
            weaknesses = cve_obj.get("weaknesses", [])
            cwe_list = extract_cwe_list(weaknesses)

            # æ„é€ ç²¾ç®€ç»“æ„
            record = {
                "id": cve_id,
                "description": description,
                "cwes": cwe_list
            }

            # åŠ å…¥å¹´ä»½ bucket
            if year not in year_buckets:
                year_buckets[year] = {}
            year_buckets[year][cve_id] = record

        # æ¯ 10 é¡µæˆ–æœ€åä¸€é¡µä¿å­˜ä¸€æ¬¡ï¼ˆé˜²å†…å­˜æº¢å‡ºï¼‰
        if (page + 1) % 10 == 0 or page == total_pages - 1:
            for y, data in year_buckets.items():
                if not data:
                    continue
                out_file = OUTPUT_DIR / f"CVE-{y}.json"
                # åˆå¹¶ï¼šè‹¥æ–‡ä»¶å·²å­˜åœ¨ï¼Œè¯»å–åæ›´æ–°
                if out_file.exists():
                    with open(out_file, "r", encoding="utf-8") as f:
                        existing = json.load(f)
                    existing.update(data)
                else:
                    existing = data
                with open(out_file, "w", encoding="utf-8") as f:
                    json.dump(existing, f, indent=2, ensure_ascii=False)
            year_buckets.clear()  # æ¸…ç©ºå†…å­˜
            print(f"[ğŸ’¾] Saved up to page {page + 1}")

    print(f"\n[âœ…] Done! Files saved to: {OUTPUT_DIR.absolute()}")


if __name__ == "__main__":
    main()
